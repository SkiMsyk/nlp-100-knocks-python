{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad41d24c-28e6-419a-a83d-93edcc4e6d82",
   "metadata": {},
   "source": [
    "# 00. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625f494f-2447-4adc-90e6-6e2e69c592ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"stressed\"\n",
    "t[-1::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c514d42-c9f9-41cc-8392-ab2a58a9bfc1",
   "metadata": {},
   "source": [
    "# 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ff5c30-8bb8-4b8f-b5e3-77f1a388e302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"パタトクカシーー\"\n",
    "''.join([e for i, e in enumerate(t) if i % 2 != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09883202-7435-4bd6-95ec-3f797844d421",
   "metadata": {},
   "source": [
    "# 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94a1dd18-d5dc-4d12-af19-a02bf8bb3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_join(t1,t2,drop=True):\n",
    "    minlen = min(len(t1), len(t2))\n",
    "    res = ''.join([e1 + e2 for e1, e2 in zip(t1[:minlen], t2[:minlen])])\n",
    "    \n",
    "    if drop:\n",
    "        return res\n",
    "    else:\n",
    "        resid = t1[minlen:] + t2[minlen:]\n",
    "        return res + resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df9661ca-2021-44b6-aaf1-3808d23c4ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = \"パトカー\"\n",
    "t2 = \"タクシー\"\n",
    "\n",
    "alternate_join(t1,t2,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03d4b7-2dd5-41fa-9d3e-95ee95a362c5",
   "metadata": {},
   "source": [
    "# 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cbaf7264-d41a-41eb-9f1d-80ac2a132e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_words(t):\n",
    "    return [e for e in re.split(r\"[,.\\s+]\", t) if e != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3c923fb-cb24-4136-b531-0eb0e720251d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "t = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "[len(e) for e in get_words(t) if e != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34c78b0-b562-4f20-8460-571a0182d19c",
   "metadata": {},
   "source": [
    "# 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14fe2408-34f8-4702-8f42-ba07d4d6655b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H',\n",
       " 'He',\n",
       " 'Li',\n",
       " 'Be',\n",
       " 'B',\n",
       " 'C',\n",
       " 'N',\n",
       " 'O',\n",
       " 'F',\n",
       " 'Ne',\n",
       " 'Na',\n",
       " 'Mi',\n",
       " 'Al',\n",
       " 'Si',\n",
       " 'P',\n",
       " 'S',\n",
       " 'Cl',\n",
       " 'Ar',\n",
       " 'K',\n",
       " 'Ca']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "[e[0] if i in [0,4,5,6,7,8,14,15,18] else e[:2] for i, e in enumerate(get_words(t))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feed2d6-1b21-447d-86d2-263d2b96f398",
   "metadata": {},
   "source": [
    "# 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "93d47edf-ee33-4475-a1ef-b287aad754f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(t,n,gram_type=\"word\"):\n",
    "    if n < 1:\n",
    "        return \"n should be greater than equal 1\"\n",
    "    if gram_type not in [\"word\", \"char\"]:\n",
    "        return \"type should be 'word' or 'char'\"\n",
    "    elif gram_type == \"word\":\n",
    "        words = get_words(t)\n",
    "        if n > len(words):\n",
    "            n = len(words)\n",
    "        res = [\"\"]*(len(words)-t+1)\n",
    "        for i in range(len(words)-n+1):\n",
    "            res[i] = words[i:i+n]\n",
    "        return res\n",
    "    elif gram_type == \"char\":\n",
    "        if n > len(t):\n",
    "            n = len(t)\n",
    "        res = [\"\"]*(len(t)-n+1)\n",
    "        for i in range(len(t)-n+1):\n",
    "            res[i] = t[i:i+n]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f170d35-499b-43d5-b34f-96a581a9abac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am an NLPer']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ngram(\"I am an NLPer\", n=20, gram_type=\"char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e281d7e4-9642-4e90-940d-d2a5d870911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"I am an NLPer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96221f6e-de79-44f3-bef7-58d76648ccb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
